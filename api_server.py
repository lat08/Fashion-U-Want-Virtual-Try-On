"""
Virtual Try-On API Server
H·ªá th·ªëng API x·ª≠ l√Ω ƒë·ªìng th·ªùi nhi·ªÅu request t·ª´ ng∆∞·ªùi d√πng
"""

import os
import sys
import uuid
import shutil
import cv2
import json
import copy
import subprocess
import numpy as np
from pathlib import Path
from typing import Optional
import asyncio
from datetime import datetime
import threading
from concurrent.futures import ThreadPoolExecutor

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# Import OpenPose PyTorch
sys.path.insert(0, str(Path("OpenPose.PyTorch").absolute()))
from src.body import Body
from src import util

# Import c√°c module x·ª≠ l√Ω
from clothseg import process_images as process_cloth_segmentation
from PIL import Image, ImageDraw
from get_parse_agnostic import get_im_parse_agnostic
from get_agnostic2 import get_img_agnostic


# =========================
# Configuration
# =========================
class Config:
    BASE_DIR = Path(__file__).parent
    OPENPOSE_MODEL_PATH = BASE_DIR / "OpenPose.PyTorch" / "model" / "pose_iter_584000.caffemodel.pt"
    TEMP_DIR = BASE_DIR / "temp_sessions"
    MAX_WORKERS = 4  # S·ªë l∆∞·ª£ng request x·ª≠ l√Ω ƒë·ªìng th·ªùi
    SESSION_CLEANUP_HOURS = 24  # X√≥a session sau 24 gi·ªù


config = Config()
config.TEMP_DIR.mkdir(exist_ok=True)

# Thread pool ƒë·ªÉ x·ª≠ l√Ω ƒë·ªìng th·ªùi
executor = ThreadPoolExecutor(max_workers=config.MAX_WORKERS)

# =========================
# Progress Tracking (in-memory)
# =========================
progress_lock = threading.Lock()
progress_state = {}
TOTAL_STEPS = 10  # High-level pipeline steps

def _now_iso() -> str:
    return datetime.utcnow().isoformat() + "Z"

def set_progress(session_id: str, *, step: int, status: str, message: str, result_url: Optional[str] = None):
    with progress_lock:
        state = progress_state.get(session_id, {})
        state.update({
            "session_id": session_id,
            "status": status,           # queued | processing | completed | error
            "message": message,
            "step": step,
            "total_steps": TOTAL_STEPS,
            "updated_at": _now_iso(),
        })
        if "started_at" not in state:
            state["started_at"] = _now_iso()
        if result_url is not None:
            state["result_url"] = result_url
        progress_state[session_id] = state

def report_progress(session_id: str, step: int, message: str):
    set_progress(session_id, step=step, status="processing", message=message)

# Kh·ªüi t·∫°o OpenPose model (global ƒë·ªÉ t√°i s·ª≠ d·ª•ng)
print("üîß Loading OpenPose model...")
body_estimation = Body(str(config.OPENPOSE_MODEL_PATH), 'body25')
print("‚úÖ OpenPose model loaded")


# =========================
# FastAPI App
# =========================
app = FastAPI(
    title="Virtual Try-On API",
    description="API for virtual clothing try-on",
    version="1.0.0"
)

# CORS ƒë·ªÉ cho ph√©p web truy c·∫≠p
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# =========================
# Constants & Helpers
# =========================
PARSE_COLOR_TO_LABEL = {
    (0, 0, 0): 0,
    (255, 0, 0): 2,
    (0, 0, 255): 13,
    (85, 51, 0): 10,
    (255, 85, 0): 5,
    (0, 255, 255): 15,
    (51, 170, 221): 14,
    (0, 85, 85): 9,
    (0, 0, 85): 6,
    (0, 128, 0): 12,
    (177, 255, 85): 17,
    (85, 255, 170): 16,
    (0, 119, 221): 5,
}

DENSEPOSE_COLORMAP = {
    2: [20, 80, 194],
    3: [4, 98, 224],
    4: [8, 110, 221],
    9: [6, 166, 198],
    10: [22, 173, 184],
    15: [145, 191, 116],
    16: [170, 190, 105],
    17: [191, 188, 97],
    18: [216, 187, 87],
    19: [228, 191, 74],
    20: [240, 198, 60],
    21: [252, 205, 47],
    22: [250, 220, 36],
    23: [251, 235, 25],
    24: [248, 251, 14],
}


def run_subprocess(command, cwd=None):
    """Execute external command with error handling"""
    try:
        result = subprocess.run(
            command,
            cwd=str(cwd) if cwd else None,
            check=True,
            capture_output=True,
            text=True
        )
        return result
    except subprocess.CalledProcessError as exc:
        print(f"‚ùå Command failed with exit code {exc.returncode}")
        if exc.stderr:
            print(f"   stderr: {exc.stderr[:500]}")
        raise


def generate_image_parse_v3(segmentation_path: Path, output_dir: Path) -> Path:
    """Convert Graphonomy RGB segmentation map to grayscale label map."""
    if not segmentation_path.exists():
        raise ValueError(f"Segmentation image not found at: {segmentation_path}")

    img = Image.open(segmentation_path).convert("RGB")
    img_array = np.array(img)
    h, w, _ = img_array.shape
    gray_img = np.zeros((h, w), dtype=np.uint8)

    for color, label in PARSE_COLOR_TO_LABEL.items():
        mask = np.all(img_array == color, axis=-1)
        gray_img[mask] = label

    resized = cv2.resize(gray_img, (768, 1024), interpolation=cv2.INTER_NEAREST)
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "00001_00.png"
    Image.fromarray(resized, "L").save(output_path)
    return output_path


def generate_densepose_outputs(session_dir: Path) -> Path:
    """Generate DensePose visualization matching get_densepose.py behavior."""
    model_path = session_dir / "model.jpg"
    data_json_path = session_dir / "data.json"

    if not model_path.exists():
        raise ValueError(f"Model image missing for DensePose: {model_path}")
    if not data_json_path.exists():
        raise ValueError(f"DensePose data.json missing at: {data_json_path}")

    img = Image.open(model_path).convert("RGB")
    img_w, img_h = img.size

    with open(data_json_path, "r") as f:
        json_data = json.load(f)

    if len(json_data) < 3:
        raise ValueError("DensePose JSON does not contain expected data")

    segmentation_data = np.array(json_data[0])
    seg_img = np.zeros((*segmentation_data.shape, 3), dtype=np.uint8)
    for key, color in DENSEPOSE_COLORMAP.items():
        seg_img[segmentation_data == key] = color

    box = list(json_data[2])
    if len(box) != 4:
        raise ValueError("DensePose bounding box has unexpected format")

    x1, y1, x2, y2 = box
    x = int(x1)
    y = int(y1)
    w = int(x2 - x1)
    h = int(y2 - y1)

    bg = np.zeros((img_h, img_w, 3), dtype=np.uint8)
    if w > 0 and h > 0:
        seg_h, seg_w = seg_img.shape[:2]
        crop_h = min(h, seg_h)
        crop_w = min(w, seg_w)
        x0 = max(0, x)
        y0 = max(0, y)
        x1_clip = min(img_w, x0 + crop_w)
        y1_clip = min(img_h, y0 + crop_h)
        bg[y0:y1_clip, x0:x1_clip, :] = seg_img[: y1_clip - y0, : x1_clip - x0, :]

    output_dir = session_dir / "HR-VITON" / "test" / "test" / "image-densepose"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "00001_00.jpg"
    Image.fromarray(bg, "RGB").save(output_path)
    return output_path


def generate_parse_agnostic_outputs(session_dir: Path):
    """Recreate get_parse_agnostic.py logic using session-scoped paths."""
    data_path = session_dir / "HR-VITON" / "test" / "test"
    image_dir = data_path / "image"
    parse_dir = data_path / "image-parse-v3"
    openpose_dir = data_path / "openpose_json"
    output_dir = data_path / "image-parse-agnostic-v3.2"
    output_dir.mkdir(parents=True, exist_ok=True)

    if not image_dir.exists() or not parse_dir.exists() or not openpose_dir.exists():
        return

    for image_path in sorted(image_dir.glob("*.jpg")):
        pose_path = openpose_dir / image_path.name.replace(".jpg", "_keypoints.json")
        parse_path = parse_dir / image_path.name.replace(".jpg", ".png")

        if not pose_path.exists() or not parse_path.exists():
            continue

        with open(pose_path, "r") as f:
            pose_label = json.load(f)

        people = pose_label.get("people", [])
        if not people:
            continue

        pose_values = people[0].get("pose_keypoints_2d", [])
        if not pose_values:
            continue

        pose_data = np.array(pose_values).reshape((-1, 3))[:, :2]
        im_parse = Image.open(parse_path)
        agnostic = get_im_parse_agnostic(im_parse, pose_data)
        agnostic.save(output_dir / parse_path.name)


def generate_human_agnostic_outputs(session_dir: Path):
    """Recreate get_agnostic2.py logic using session-scoped paths."""
    data_path = session_dir / "HR-VITON" / "test" / "test"
    image_dir = data_path / "image"
    parse_dir = data_path / "image-parse-v3"
    openpose_dir = data_path / "openpose_json"
    output_dir = data_path / "agnostic-v3.2"
    output_dir.mkdir(parents=True, exist_ok=True)

    if not image_dir.exists() or not parse_dir.exists() or not openpose_dir.exists():
        return

    for image_path in sorted(image_dir.glob("*.jpg")):
        pose_path = openpose_dir / image_path.name.replace(".jpg", "_keypoints.json")
        parse_path = parse_dir / image_path.name.replace(".jpg", ".png")

        if not pose_path.exists() or not parse_path.exists():
            continue

        with open(pose_path, "r") as f:
            pose_label = json.load(f)

        people = pose_label.get("people", [])
        if not people:
            continue

        pose_values = people[0].get("pose_keypoints_2d", [])
        if not pose_values:
            continue

        pose_data = np.array(pose_values).reshape((-1, 3))[:, :2]
        im = Image.open(image_path).convert("RGB")
        im_parse = Image.open(parse_path)
        agnostic = get_img_agnostic(im, im_parse, pose_data.copy())
        agnostic.save(output_dir / image_path.name)


# =========================
# Models
# =========================
class TryOnRequest(BaseModel):
    session_id: str
    background: bool = True


class TryOnResponse(BaseModel):
    session_id: str
    status: str
    message: str
    result_image_url: Optional[str] = None


# =========================
# Helper Functions
# =========================
def create_session_dir(session_id: str) -> Path:
    """T·∫°o th∆∞ m·ª•c ri√™ng cho m·ªói session"""
    session_dir = config.TEMP_DIR / session_id
    session_dir.mkdir(exist_ok=True)
    
    # T·∫°o c√°c th∆∞ m·ª•c con c·∫ßn thi·∫øt
    (session_dir / "input").mkdir(exist_ok=True)
    (session_dir / "output").mkdir(exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "image").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "cloth").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "cloth-mask").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "openpose_img").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "openpose_json").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "image-parse-v3").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "image-parse-agnostic-v3.2").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "agnostic-v3.2").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "test" / "test" / "image-densepose").mkdir(parents=True, exist_ok=True)
    (session_dir / "HR-VITON" / "Output").mkdir(parents=True, exist_ok=True)
    
    return session_dir

# work
def process_openpose(image_path: Path, session_dir: Path) -> dict:
    """
    X·ª≠ l√Ω OpenPose s·ª≠ d·ª•ng PyTorch (thay th·∫ø OpenPose C++)
    """
    print(f"üîç Processing OpenPose for session: {session_dir.name}")
    print(f"   Image path: {image_path}")
    print(f"   Image exists: {image_path.exists()}")
    
    if not image_path.exists():
        raise ValueError(f"Image not found at: {image_path}")
    
    # ƒê·ªçc ·∫£nh
    oriImg = cv2.imread(str(image_path))
    if oriImg is None:
        raise ValueError(f"Cannot read image: {image_path}")
    
    print(f"   Image shape: {oriImg.shape}")
    
    # Resize v·ªÅ 768x1024
    if oriImg.shape[:2] != (1024, 768):
        print(f"   Resizing from {oriImg.shape[:2]} to (1024, 768)")
        oriImg = cv2.resize(oriImg, (768, 1024))
    else:
        print(f"   Already correct size")
    
    # Detect pose
    candidate, subset = body_estimation(oriImg)
    
    if len(subset) == 0:
        raise ValueError("No person detected in image")
    
    # T·∫°o output directories
    openpose_img_dir = session_dir / "HR-VITON" / "test" / "test" / "openpose_img"
    openpose_json_dir = session_dir / "HR-VITON" / "test" / "test" / "openpose_json"
    
    # V·∫Ω skeleton
    canvas = copy.deepcopy(oriImg)
    canvas = util.draw_bodypose(canvas, candidate, subset, 'body25')
    
    # L∆∞u visualization
    output_img_path = openpose_img_dir / "00001_00_rendered.png"
    cv2.imwrite(str(output_img_path), canvas)
    
    # Convert sang JSON format
    result = {
        "version": 1.3,
        "people": []
    }
    
    for person in subset:
        person_keypoints = []
        for i in range(25):  # Body25 c√≥ 25 keypoints
            idx = int(person[i])
            if idx == -1:
                person_keypoints.extend([0, 0, 0])
            else:
                x, y, score = candidate[idx][:3]
                person_keypoints.extend([float(x), float(y), float(score)])
        
        result["people"].append({
            "person_id": [-1],
            "pose_keypoints_2d": person_keypoints,
            "face_keypoints_2d": [],
            "hand_left_keypoints_2d": [],
            "hand_right_keypoints_2d": [],
            "pose_keypoints_3d": [],
            "face_keypoints_3d": [],
            "hand_left_keypoints_3d": [],
            "hand_right_keypoints_3d": []
        })
    
    # L∆∞u JSON
    output_json_path = openpose_json_dir / "00001_00_keypoints.json"
    with open(output_json_path, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"‚úÖ OpenPose completed: {len(result['people'])} person(s) detected")
    return result


# work
def process_cloth_mask(session_dir: Path):
    """X·ª≠ l√Ω cloth segmentation"""
    print(f"üëî Processing cloth segmentation for session: {session_dir.name}")
    
    input_path = str(session_dir / "input" / "cloth.jpg")
    cloth_output = str(session_dir / "HR-VITON" / "test" / "test" / "cloth")
    mask_output = str(session_dir / "HR-VITON" / "test" / "test" / "cloth-mask")
    
    print(f"   Input: {input_path}")
    print(f"   Input exists: {Path(input_path).exists()}")
    print(f"   Cloth output: {cloth_output}")
    print(f"   Mask output: {mask_output}")
    
    if not Path(input_path).exists():
        raise ValueError(f"Cloth image not found at: {input_path}")
    
    process_cloth_segmentation(
        input_path=input_path,
        cloth_output_path=cloth_output,
        mask_output_path=mask_output
    )
    print("‚úÖ Cloth segmentation completed")


def process_segmentation(session_dir: Path):
    """X·ª≠ l√Ω Graphonomy semantic segmentation"""
    print(f"üé® Processing semantic segmentation for session: {session_dir.name}")
    
    # Use the resized_img.jpg that was created earlier (384x512)
    resized_path = session_dir / "resized_img.jpg"
    print(f"   Resized image path: {resized_path}")
    print(f"   Resized image exists: {resized_path.exists()}")
    
    if not resized_path.exists():
        # Fallback: create it if not exists
        print(f"   WARNING: resized_img.jpg not found, creating it...")
        model_img = cv2.imread(str(session_dir / "input" / "model.jpg"))
        if model_img is None:
            raise ValueError("Cannot read model image for segmentation")
        resized = cv2.resize(model_img, (384, 512))
        cv2.imwrite(str(resized_path), resized)
        print(f"   Created resized_img.jpg")
    
    # Run Graphonomy
    graphonomy_dir = config.BASE_DIR / "Graphonomy-master"
    graphonomy_script = graphonomy_dir / "exp" / "inference" / "inference.py"
    inference_model = graphonomy_dir / "inference.pth"
    output_path = session_dir / "resized_segmentation_img.png"
    
    print(f"   Graphonomy dir: {graphonomy_dir}")
    print(f"   Script: {graphonomy_script}")
    print(f"   Model: {inference_model}")
    print(f"   Model exists: {inference_model.exists()}")
    
    command = [
        sys.executable,
        str(graphonomy_script),
        "--loadmodel", str(inference_model),
        "--img_path", str(resized_path),
        "--output_path", str(session_dir),
        "--output_name", "resized_segmentation_img",
    ]
    print(f"   Running Graphonomy inference")
    run_subprocess(command, cwd=graphonomy_dir)
    
    print(f"   Checking output: {output_path}")
    print(f"   Output exists: {output_path.exists()}")
    
    if not output_path.exists():
        raise ValueError(f"Graphonomy failed to generate output at: {output_path}")
    
    # Read the original model image (768x1024) for mask processing
    model_path = session_dir / "model.jpg"
    print(f"   Reading model for mask: {model_path}")
    model_img = cv2.imread(str(model_path))
    if model_img is None:
        raise ValueError(f"Cannot read model image from: {model_path}")
    
    print(f"   Model shape: {model_img.shape}")
    
    # X·ª≠ l√Ω segmentation mask
    mask_img = cv2.imread(str(output_path), cv2.IMREAD_GRAYSCALE)
    if mask_img is None:
        raise ValueError(f"Cannot read segmentation output from: {output_path}")
    
    print(f"   Mask shape before resize: {mask_img.shape}")
    mask_img = cv2.resize(mask_img, (768, 1024))
    print(f"   Mask shape after resize: {mask_img.shape}")
    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    mask_img = cv2.erode(mask_img, k)
    
    # L∆∞u mask ƒë·ªÉ d√πng sau
    mask_path = session_dir / "segmentation_mask.png"
    cv2.imwrite(str(mask_path), mask_img)
    
    # Remove background - matching main.py logic exactly
    img_seg = cv2.bitwise_and(model_img, model_img, mask=mask_img)
    back_ground = model_img - img_seg
    img_seg = np.where(img_seg == 0, 215, img_seg)
    
    # L∆∞u background ƒë·ªÉ d√πng sau
    bg_path = session_dir / "background.png"
    cv2.imwrite(str(bg_path), back_ground)
    
    # Save seg_img.png (matching main.py)
    seg_img_path = session_dir / "seg_img.png"
    cv2.imwrite(str(seg_img_path), img_seg)
    
    # Resize and save to HR-VITON directory (already 768x1024, but main.py does this)
    img = cv2.resize(img_seg, (768, 1024))
    seg_path = session_dir / "HR-VITON" / "test" / "test" / "image" / "00001_00.jpg"
    cv2.imwrite(str(seg_path), img)
    
    # Convert segmentation colors to grayscale labels
    parse_v3_dir = session_dir / "HR-VITON" / "test" / "test" / "image-parse-v3"
    generate_image_parse_v3(output_path, parse_v3_dir)
    
    print("‚úÖ Semantic segmentation completed")
    return mask_img, back_ground


def process_densepose(session_dir: Path):
    """X·ª≠ l√Ω DensePose"""
    print(f"ü¶¥ Processing DensePose for session: {session_dir.name}")
    
    model_path = session_dir / "model.jpg"  # Use resized model image
    output_pkl = session_dir / "output.pkl"
    output_json = session_dir / "data.json"
    densepose_output_dir = session_dir / "HR-VITON" / "test" / "test" / "image-densepose"
    
    print(f"   Model path: {model_path}")
    print(f"   Model exists: {model_path.exists()}")
    print(f"   Output pkl: {output_pkl}")
    print(f"   Output json: {output_json}")
    print(f"   Output dir: {densepose_output_dir}")
    
    if not model_path.exists():
        raise ValueError(f"Model image not found at: {model_path}")
    
    detectron2_dir = config.BASE_DIR / "detectron2"
    apply_net_script = detectron2_dir / "projects" / "DensePose" / "apply_net.py"
    densepose_config = detectron2_dir / "projects" / "DensePose" / "configs" / "densepose_rcnn_R_50_FPN_s1x.yaml"
    
    print(f"   Detectron2 dir: {detectron2_dir}")
    print(f"   Apply net script: {apply_net_script}")
    print(f"   Script exists: {apply_net_script.exists()}")
    print(f"   Config: {densepose_config}")
    print(f"   Config exists: {densepose_config.exists()}")
    
    # Run DensePose
    command = [
        sys.executable,
        str(apply_net_script),
        "dump",
        str(densepose_config),
        "https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl",
        str(model_path),
        "--output", str(output_pkl),
        "-v",
    ]
    print("   Running DensePose apply_net...")
    run_subprocess(command, cwd=session_dir)
    
    # Check if data.json was created
    if not output_json.exists():
        raise ValueError(f"Failed to generate data.json from DensePose at: {output_json}")
    
    print(f"   JSON created: {output_json}")
    
    # Generate DensePose visualization
    generate_densepose_outputs(session_dir)
    
    print("‚úÖ DensePose completed")


def process_parse_agnostic(session_dir: Path):
    """X·ª≠ l√Ω parse agnostic"""
    print(f"üìê Processing parse agnostic for session: {session_dir.name}")
    generate_parse_agnostic_outputs(session_dir)
    print("‚úÖ Parse agnostic completed")


def process_human_agnostic(session_dir: Path):
    """X·ª≠ l√Ω human agnostic"""
    print(f"üßç Processing human agnostic for session: {session_dir.name}")
    generate_human_agnostic_outputs(session_dir)
    print("‚úÖ Human agnostic completed")


def process_hrviton(session_dir: Path):
    """Ch·∫°y HR-VITON ƒë·ªÉ t·∫°o ·∫£nh k·∫øt qu·∫£"""
    print(f"üéØ Running HR-VITON for session: {session_dir.name}")
    
    hrviton_dir = config.BASE_DIR / "HR-VITON"
    dataroot = session_dir / "HR-VITON" / "test"
    session_output_dir = session_dir / "HR-VITON" / "Output"
    session_output_dir.mkdir(parents=True, exist_ok=True)
    
    # Clear previous outputs for this session
    for png_file in session_output_dir.glob("*.png"):
        png_file.unlink()
    
    # T·∫°o file test list
    test_list = dataroot / "test_pairs.txt"
    with open(test_list, 'w') as f:
        f.write("00001_00.jpg 00001_00.jpg\n")
    
    # Run HR-VITON with absolute paths
    command = [
        sys.executable,
        "test_generator.py",
        "--cuda", "True",
        "--test_name", session_dir.name,
        "--tocg_checkpoint", "mtviton.pth",
        "--gpu_ids", "0",
        "--gen_checkpoint", "gen.pth",
        "--datasetting", "unpaired",
        "--data_list", "test_pairs.txt",
        "--dataroot", str(dataroot),
        "--output_dir", str(session_output_dir),
    ]
    run_subprocess(command, cwd=hrviton_dir)
    print("‚úÖ HR-VITON completed")


def add_background(result_img_path: Path, mask_img: np.ndarray, background: np.ndarray, add_bg: bool):
    """Th√™m background v√†o ·∫£nh k·∫øt qu·∫£"""
    img = cv2.imread(str(result_img_path))
    
    if add_bg:
        img = cv2.bitwise_and(img, img, mask=mask_img)
        img = img + background
    
    return img


def full_pipeline(session_dir: Path, add_background_flag: bool = True, progress_cb=None, session_id: Optional[str] = None):
    """Pipeline x·ª≠ l√Ω ƒë·∫ßy ƒë·ªß - Following exact logic from main.py"""
    try:
        current_step = 0
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Starting pipeline")
        # 1. Resize model image to (768, 1024)
        print(f"üìè Step 1: Resizing model image...")
        current_step = 1
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Resizing model image (768x1024)")
        model_path = session_dir / "input" / "model.jpg"
        print(f"   Reading from: {model_path}")
        print(f"   File exists: {model_path.exists()}")
        
        if not model_path.exists():
            raise ValueError(f"Model image not found at: {model_path}")
        
        model_img = cv2.imread(str(model_path))
        if model_img is None:
            raise ValueError(f"Cannot read model image from: {model_path}")
        
        print(f"   Original shape: {model_img.shape}")
            
        if model_img.shape[:2] != (1024, 768):
            model_img = cv2.resize(model_img, (768, 1024))
            print(f"   Resized to (768, 1024)")
        else:
            print(f"   Already (768, 1024)")
            
        model_resized_path = session_dir / "model.jpg"
        cv2.imwrite(str(model_resized_path), model_img)
        print(f"   Saved to: {model_resized_path}")
        
        # 1b. Create resized_img.jpg (384x512) for Graphonomy - IMPORTANT: Main.py does this early
        print(f"üìè Step 1b: Creating resized_img.jpg (384x512)...")
        current_step = 2
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Preparing resized image (384x512) for Graphonomy")
        print(f"   Reading from: {model_resized_path}")
        
        img_384_512 = cv2.imread(str(model_resized_path))
        if img_384_512 is None:
            raise ValueError(f"Cannot read resized model image from: {model_resized_path}")
        
        print(f"   Shape before resize: {img_384_512.shape}")
        img_384_512 = cv2.resize(img_384_512, (384, 512))
        print(f"   Shape after resize: {img_384_512.shape}")
        
        resized_img_path = session_dir / "resized_img.jpg"
        cv2.imwrite(str(resized_img_path), img_384_512)
        print(f"   Saved to: {resized_img_path}")
        
        # 2. Process cloth segmentation
        print(f"\n{'='*60}")
        current_step = 3
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Running cloth segmentation")
        process_cloth_mask(session_dir)
        
        # 3. Process OpenPose (thay th·∫ø OpenPose C++)
        print(f"\n{'='*60}")
        current_step = 4
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Running OpenPose (PyTorch)")
        process_openpose(model_resized_path, session_dir)
        
        # 4. Process semantic segmentation (includes grayscale conversion)
        print(f"\n{'='*60}")
        current_step = 5
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Running Graphonomy segmentation")
        mask_img, back_ground = process_segmentation(session_dir)
        
        # 5. Process DensePose
        print(f"\n{'='*60}")
        current_step = 6
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Running DensePose")
        process_densepose(session_dir)
        
        # 6. Process parse agnostic
        print(f"\n{'='*60}")
        current_step = 7
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Generating parse agnostic")
        process_parse_agnostic(session_dir)
        
        # 7. Process human agnostic
        print(f"\n{'='*60}")
        current_step = 8
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Generating human agnostic")
        process_human_agnostic(session_dir)
        
        # 8. Run HR-VITON
        print(f"\n{'='*60}")
        current_step = 9
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Running HR-VITON generator")
        process_hrviton(session_dir)
        
        # 9. Find result image(s) - Process ALL results like main.py
        print(f"\n{'='*60}")
        print("üñºÔ∏è Step 9: Processing final result(s)...")
        current_step = 10
        if progress_cb and session_id:
            progress_cb(session_id, current_step, "Finalizing result images")
        output_dir = session_dir / "HR-VITON" / "Output"
        result_files = sorted(output_dir.glob("*.png"))
        
        if not result_files:
            raise ValueError("No result image generated")
        
        print(f"   Found {len(result_files)} result file(s)")
        
        # 10. Process all result files (like main.py's loop through glob results)
        final_output_paths = []
        for idx, result_img_path in enumerate(result_files):
            print(f"   Processing result {idx+1}/{len(result_files)}: {result_img_path.name}")
            
            # Add background if needed
            final_img = add_background(result_img_path, mask_img, back_ground, add_background_flag)
            
            # Save to session output
            if len(result_files) == 1:
                final_output_path = session_dir / "output" / "final_result.png"
            else:
                final_output_path = session_dir / "output" / f"final_result_{idx}.png"
            
            cv2.imwrite(str(final_output_path), final_img)
            final_output_paths.append(final_output_path)
            
            # Also update the original file in HR-VITON/Output (matching main.py behavior)
            cv2.imwrite(str(result_img_path), final_img)
        
        print(f"\n{'='*60}")
        print(f"üéâ Processing completed for session: {session_dir.name}")
        print(f"   Generated {len(final_output_paths)} final image(s)")
        
        # Return first result path (or list if multiple)
        return final_output_paths[0] if len(final_output_paths) == 1 else final_output_paths
        
    except Exception as e:
        print(f"\n{'='*60}")
        print(f"‚ùå Error in pipeline: {str(e)}")
        print(f"Error type: {type(e).__name__}")
        import traceback
        print("\nFull traceback:")
        traceback.print_exc()
        print(f"{'='*60}")
        raise


# =========================
# API Endpoints
# =========================
@app.get("/")
async def root():
    return {
        "message": "Virtual Try-On API",
        "version": "1.0.0",
        "endpoints": {
            "upload_images": "/upload",
            "process": "/process/{session_id}",
            "result": "/result/{session_id}",
            "health": "/health"
        }
    }


@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "openpose_model_loaded": body_estimation is not None
    }


@app.post("/upload")
async def upload_images(
    model_image: UploadFile = File(..., description="·∫¢nh ng∆∞·ªùi m·∫´u"),
    cloth_image: UploadFile = File(..., description="·∫¢nh qu·∫ßn √°o")
):
    """
    Upload ·∫£nh ng∆∞·ªùi m·∫´u v√† qu·∫ßn √°o
    Returns: session_id ƒë·ªÉ track request
    """
    # T·∫°o session ID unique
    session_id = str(uuid.uuid4())
    session_dir = create_session_dir(session_id)
    
    try:
        # L∆∞u model image
        model_path = session_dir / "input" / "model.jpg"
        with open(model_path, "wb") as f:
            content = await model_image.read()
            f.write(content)
        
        # L∆∞u cloth image
        cloth_path = session_dir / "input" / "cloth.jpg"
        with open(cloth_path, "wb") as f:
            content = await cloth_image.read()
            f.write(content)
        
        return {
            "session_id": session_id,
            "status": "uploaded",
            "message": "Images uploaded successfully. Use /process/{session_id} to start processing."
        }
        
    except Exception as e:
        # Cleanup n·∫øu c√≥ l·ªói
        shutil.rmtree(session_dir, ignore_errors=True)
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")


@app.post("/process/{session_id}")
async def process_tryon(
    session_id: str,
    background_tasks: BackgroundTasks,
    add_background: bool = True
):
    """
    X·ª≠ l√Ω virtual try-on
    """
    session_dir = config.TEMP_DIR / session_id
    
    if not session_dir.exists():
        raise HTTPException(status_code=404, detail="Session not found")
    
    # Check if images exist
    model_path = session_dir / "input" / "model.jpg"
    cloth_path = session_dir / "input" / "cloth.jpg"
    
    if not model_path.exists() or not cloth_path.exists():
        raise HTTPException(status_code=400, detail="Images not found. Please upload first.")
    
    # Initialize progress state and start background job
    set_progress(session_id, step=0, status="queued", message="Queued for processing")

    def _job():
        try:
            set_progress(session_id, step=0, status="processing", message="Starting processing")
            result = full_pipeline(session_dir, add_background_flag=add_background, progress_cb=report_progress, session_id=session_id)
            set_progress(session_id, step=TOTAL_STEPS, status="completed", message="Completed", result_url=f"/result/{session_id}")
        except Exception as e:
            # Preserve last known step on error
            with progress_lock:
                last_step = progress_state.get(session_id, {}).get("step", 0)
            set_progress(session_id, step=last_step, status="error", message=f"Error: {str(e)}")

    executor.submit(_job)

    return {
        "session_id": session_id,
        "status": "processing",
        "message": "Processing started",
        "progress_url": f"/progress/{session_id}",
        "result_url": f"/result/{session_id}"
    }


@app.get("/result/{session_id}")
async def get_result(session_id: str):
    """
    L·∫•y ·∫£nh k·∫øt qu·∫£
    """
    result_path = config.TEMP_DIR / session_id / "output" / "final_result.png"
    
    if not result_path.exists():
        raise HTTPException(status_code=404, detail="Result not found or processing not completed")
    
    return FileResponse(
        result_path,
        media_type="image/png",
        filename=f"tryon_result_{session_id}.png"
    )


@app.get("/progress/{session_id}")
async def get_progress(session_id: str):
    """Tr·∫£ v·ªÅ ti·∫øn ƒë·ªô x·ª≠ l√Ω cho FE polling"""
    with progress_lock:
        state = progress_state.get(session_id)
    if not state:
        raise HTTPException(status_code=404, detail="Session not found")
    return state


@app.delete("/session/{session_id}")
async def delete_session(session_id: str):
    """
    X√≥a session v√† d·ªçn d·∫πp file
    """
    session_dir = config.TEMP_DIR / session_id
    
    if not session_dir.exists():
        raise HTTPException(status_code=404, detail="Session not found")
    
    try:
        shutil.rmtree(session_dir)
        return {
            "session_id": session_id,
            "status": "deleted",
            "message": "Session cleaned up successfully"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Cleanup failed: {str(e)}")


# =========================
# Main
# =========================
if __name__ == "__main__":
    # Ch·∫°y server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        workers=1  # D√πng 1 worker v√¨ ƒë√£ c√≥ ThreadPoolExecutor
    )
